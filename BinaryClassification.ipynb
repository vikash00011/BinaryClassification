{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BinaryClassification.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vikash00011/BinaryClassification/blob/master/BinaryClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nipGMsw9p6Re",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#importing important modules/liberaries\n",
        "\n",
        "\n",
        "from sklearn.datasets import fetch_openml\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vsxupo2FzVOB",
        "colab_type": "text"
      },
      "source": [
        "Figure 3-1 shows a few more images from the MNIST dataset to give you a feel for\n",
        "the complexity of the classification task.\n",
        "\n",
        "(https://github.com/vikash00011/BinaryClassification/blob/master/Capture2.PNG)\n",
        "\n",
        "Figure 3-1. A few digits from the MNIST dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ZBMnZnwqI1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = fetch_openml('mnist_784', version=1)    #loading our sample data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_V1PD4O7qI4V",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X, y = mnist[\"data\"], mnist[\"target\"]           \n",
        "#spliting sample data in features(X) and target(y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwPlUYKtu2Tk",
        "colab_type": "text"
      },
      "source": [
        "Now, we will lookup about the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SKZBw_owqI7J",
        "colab_type": "code",
        "outputId": "a4481fb0-0f84-45bb-fb87-8d63fe7a0a56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(X.shape)   \n",
        "# 784 because each image is a 28*28 pixels, and each feature \n",
        "# simply represents one pixel’s intensity, from 0 (white) to\n",
        "# 255 (black) shape is (sample,features(28*28))\n",
        "\n",
        "print(y.shape)   \n",
        "# All are target as 1d np array so shape is (70000,)\n",
        "\n",
        "print(type(y[0]))       \n",
        "# looking the data type of the target\n",
        "\n",
        "print(type(X[0][0]))    \n",
        "# type of X is already in float format"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(70000, 784)\n",
            "(70000,)\n",
            "<class 'str'>\n",
            "<class 'numpy.float64'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w42qfCX-qI-D",
        "colab_type": "code",
        "outputId": "268e98d3-9ad0-4ffa-e09d-7be55a0b873a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y = y.astype(np.uint8)  \n",
        "#type change from str to int\n",
        "\n",
        "print(type(y[0]))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'numpy.uint8'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-67zcKJpqJD3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_test, y_train, y_test = X[:60000], X[60000:], y[:60000], y[60000:]   \n",
        "#splitting the samples in traing and testing"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tU3e1CvJqJKN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "sgd_clf = SGDClassifier(random_state=42)  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oZ5QxgkLxtz_",
        "colab_type": "text"
      },
      "source": [
        "This classifier has the advantage of being capable of handling very large datasets efficiently.This is in part because SGD deals with training instances independently, one at a time (which also makes SGD well suited for online learning).The SGDClassifier relies on randomness during training (hence the name “stochastic”). If you want reproducible results, you should set the random_state parameter."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCbFmG5_qJNA",
        "colab_type": "code",
        "outputId": "01cc7251-d925-4870-9d66-725048bb68a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "sgd_clf.fit(X_train,y_train)      \n",
        "#Training our classifier"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
              "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
              "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
              "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
              "              power_t=0.5, random_state=42, shuffle=True, tol=0.001,\n",
              "              validation_fraction=0.1, verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Dx8JX2NqJP9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "some_digit = X[0]\n",
        "some_digit_image = some_digit.reshape(28, 28)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fya5F9_gqJTI",
        "colab_type": "code",
        "outputId": "6adc86de-cd8f-4a68-a393-677d38e555b5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "sgd_clf.predict([some_digit])    \n",
        "# doing prediction"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3], dtype=uint8)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tlRzkWT1fDK",
        "colab_type": "code",
        "outputId": "b51734de-12db-4c64-e3e2-4c3988d701fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        }
      },
      "source": [
        "plt.imshow(some_digit_image, cmap = mpl.cm.binary, interpolation=\"nearest\")\n",
        "plt.axis(\"off\")\n",
        "plt.show()\n",
        "\n",
        "# Just checking what actual image is there at the location which we are predicting"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAPsAAAD4CAYAAAAq5pAIAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nsUMIsUMIsUOIfwGsbAOpXUu9/QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDZc47Ce2CeM",
        "colab_type": "text"
      },
      "source": [
        "Heyyy........ Our prediction is not accurate , righr? But to See the overall accuracy of the model we should fetch a generalized mapping of the accuracy. So we will see these in followings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAm92P4D2kNc",
        "colab_type": "text"
      },
      "source": [
        "**Performance Measures**\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LUkLs-A2vxN",
        "colab_type": "text"
      },
      "source": [
        "a.) Measuring Accuracy Using Cross-Validation.\n",
        "\n",
        "**_________**  **_________**  **_________**  **_________**  **_________**  **_________**  **_________**  **_________**  **_________**  **_________**\n",
        "\n",
        "A good way to evaluate a model is to use cross-validation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBcc8A0e1fGN",
        "colab_type": "code",
        "outputId": "dfaa44e9-313f-4240-d8f1-d14378b8a5dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")  \n",
        "# cv=3 means we are splitting samples in 3 folds.                                                                      \n",
        "# then making predictions and evaluating them on each fold \n",
        "# using a model trained on the remaining folds"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.87082583, 0.87089354, 0.88628294])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w-VJDZr-I9X9",
        "colab_type": "text"
      },
      "source": [
        "These are the accuries on fold 1 to fold 3, we can get the mean to see average accuracy.\n",
        "\n",
        "This demonstrates why accuracy is generally not the preferred performance measure\n",
        "for classifiers, especially when you are dealing with skewed datasets (i.e., when some classes are much more frequent than others).\n",
        "\n",
        "**_________**  **_________**  **_________**  **_________**  **_________**  **_________**  **_________**  **_________**  **_________**  **_________**  **_________**  **_________**  **_________**  **_________**  **_________**  **_________**  **_________**  **_________**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ilh6m916JJG5",
        "colab_type": "text"
      },
      "source": [
        "b.) Confusion Matrix\n",
        "\n",
        "**_________**  **_________**  **_________**  **_________**  **_________**\n",
        "\n",
        "A much better way to evaluate the performance of a classifier is to look at the confusion matrix. The general idea is to count the number of times instances of class A are classified as class B. For example, to know the number of times the classifier confused images of 5s with 3s, you would look in the 5th row and 3rd column of the confusion matrix.\n",
        "\n",
        "To compute the confusion matrix, you first need to have a set of predictions, so they can be compared to the actual targets. You could make predictions on the test set, but let’s keep it untouched for now (remember that you want to use the test set only at the very end of your project, once you have a classifier that you are ready to launch).Instead, you can use the cross_val_predict() function:\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "it9jgisoLl-F",
        "colab_type": "text"
      },
      "source": [
        "Instead of returning the evaluation scores, it returns the predictions made on each test fold. This means that you get a clean prediction for each instance in the training set (“clean” meaning that the prediction is made by a model\n",
        "that never saw the data during training).\n",
        "\n",
        "Now you are ready to get the confusion matrix using the confusion_matrix() function. Just pass it the target classes (y_train_5) and the predicted classes\n",
        "(pred)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKsRJxAv1fPg",
        "colab_type": "code",
        "outputId": "8c17cf87-9343-4fd0-ff05-f836d5d8cddf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "y_train_5 = (y_train == 5)  \n",
        "#Just checking labels are 5 or not, in both training and testing data\n",
        "\n",
        "y_test_5  = (y_test == 5)   \n",
        "#and assigning them to a new variables to work on confusion matrix \n",
        "\n",
        "print(y_train_5.shape)\n",
        "print(y_test_5.shape)\n",
        "\n",
        "print(y_train_5)\n",
        "print(y_test_5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(60000,)\n",
            "(10000,)\n",
            "[ True False False ...  True False False]\n",
            "[False False False ... False  True False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y-S_00kzS7uH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import cross_val_predict\n",
        "\n",
        "pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gYseT9711fSU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "cnf_mtx=confusion_matrix(y_train_5,pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t4PrFlBL1fVg",
        "colab_type": "code",
        "outputId": "8d58fe7f-17a9-45bf-e8be-dc27fe9993a4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "print(cnf_mtx.shape)\n",
        "print()\n",
        "\n",
        "cnf_mtx"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(2, 2)\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[53892,   687],\n",
              "       [ 1891,  3530]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5XUxWpNLPssZ",
        "colab_type": "text"
      },
      "source": [
        "Each row in a confusion matrix represents an actual class, while each column represents a predicted class. The first row of this matrix considers non-5 images (the negative class): 53,892 of them were correctly classified as non-5s (they are called true negatives), while the remaining 687 were wrongly classified as 5s (false positives).\n",
        "\n",
        "The second row considers the images of 5s (the positive class): 1,891 were wrongly classified as non-5s (false negatives), while the remaining 3530 were correctly classified as 5s (true positives). A perfect classifier would have only true positives and true negatives, so its confusion matrix would have nonzero values only on its main diagonal (top left to bottom right).\n",
        "\n",
        "A perfect matrix will be like below:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NXRSZccpPYot",
        "colab_type": "code",
        "outputId": "5e41444b-0243-4364-94ad-3148c27ad4d7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "perfect=y_train_5\n",
        "\n",
        "confusion_matrix(perfect,y_train_5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[54579,     0],\n",
              "       [    0,  5421]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43xxZBA90TwJ",
        "colab_type": "text"
      },
      "source": [
        "If you are confused about the confusion matrix, Figure 3-2 may help.\n",
        "\n",
        "(https://github.com/vikash00011/BinaryClassification/blob/master/Capture3.PNG)\n",
        "\n",
        "Figure 3-2. An illustrated confusion matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "la5m5JwnT8R-",
        "colab_type": "text"
      },
      "source": [
        "c.) Precision and Recall\n",
        "\n",
        "**_______________**  **_______________**  **_______________**  **_______________**  **_______________**  **_______________**  **_______________**\n",
        "\n",
        "The confusion matrix gives you a lot of information, but sometimes you may prefer a more concise metric. An interesting one to look at is the accuracy of the positive predictions; this is called the **precision** of the classifier.\n",
        "\n",
        "**precision = TP/(TP+FP)**\n",
        "\n",
        "A perfect precision is to make one single positive prediction and ensure it is correct (precision = 1/1 = 100%). This would not be very useful since the classifier would ignore all but one positive instance. So precision is typically used along with another metric named **recall, also called sensitivity or true positive rate (TPR)**.\n",
        "\n",
        "**TPR = TP/(TP+FN)**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WqnFDVwAPYrt",
        "colab_type": "code",
        "outputId": "74bf949e-2959-4801-967b-41300532293d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "from sklearn.metrics import precision_score, recall_score\n",
        "\n",
        "print(precision_score(y_train_5,pred))\n",
        "\n",
        "print()\n",
        "\n",
        "print(recall_score(y_train_5,pred))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8370879772350012\n",
            "\n",
            "0.6511713705958311\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiGT4zdhWq_U",
        "colab_type": "text"
      },
      "source": [
        "Now your 5-detector does not look as shiny as it did when you looked at its accuracy. When it claims an image represents a 5, it is correct only 83.71% of the time. Moreover, it only detects 65.12.0% of the 5s.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MJMouu1BXkj8",
        "colab_type": "text"
      },
      "source": [
        "d.) F1 Score\n",
        "\n",
        "**_______________**  **_______________**  **_______________**  **_______________**\n",
        "\n",
        "It is often convenient to combine precision and recall into a single metric called the F1 score, in particular if you need a simple way to compare two classifiers. The F1 score is the harmonic mean of precision and recall.\n",
        "\n",
        "Whereas the regular mean treats all values equally, the harmonic mean gives much more weight to low values. As a result, the classifier will only get a high F1 score if both recall and precision are high.\n",
        "\n",
        "**F1=**2/(1/precision)+(1/recall)=2*[(precision*recall)/(precision+recall)]\n",
        "                             =TP/[TP+(FN+FP/2)]\n",
        "                             \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UIw7XrIpPYvP",
        "colab_type": "code",
        "outputId": "4206d0f1-6680-423d-e62a-dccf8a3cffe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(y_train_5,pred)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7325171197343846"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P6aZTTf5ZuIQ",
        "colab_type": "text"
      },
      "source": [
        "The F1 score favors classifiers that have similar precision and recall. This is not always what you want: in some contexts you mostly care about precision, and in other contexts you really care about recall. For example, if you trained a classifier to detect videos that are safe for kids, you would probably prefer a classifier that rejects many good videos (low recall) but keeps only safe ones (high precision), rather than a classifier that has a much higher recall but lets a few really bad videos show up in your product (in such cases, you may even want to add a human pipeline to check the classifier’s video selection). On the other hand, suppose you train a classifier to detect shoplifters on surveillance images: it is probably fine if your classifier has only 30% precision as long as it has 99% recall (sure, the security guards will get a few false alerts, but almost all shoplifters will get caught).\n",
        "\n",
        "Unfortunately, you can’t have it both ways: increasing precision reduces recall, and vice versa. This is called the **precision/recall tradeoff**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMTOolp_t8ix",
        "colab_type": "text"
      },
      "source": [
        "**Precision/Recall Tradeoff**\n",
        "\n",
        "To understand this tradeoff, let’s look at how the SGDClassifier makes its classification decisions. For each instance, it computes a score based on a decision function, and if that score is greater than a threshold, it assigns the instance to the positive class, or else it assigns it to the negative class. Figure 3-3 shows a few digits positioned from the lowest score on the left to the highest score on the right. Suppose the decision threshold is positioned at the central arrow (between the two 5s): you will find 4 true positives (actual 5s) on the right of that threshold, and one false positive (actually a 6). Therefore, with that threshold, the precision is 80% (4 out of 5). But out of 6 actual 5s, the classifier only detects 4, so the recall is 67% (4 out of 6). Now if you raise the threshold (move it to the arrow on the right), the false positive (the 6) becomes a true negative, thereby increasing precision (up to 100% in this case), but one true positive becomes a false negative, decreasing recall down to 50%. Conversely, lowering the threshold increases recall and reduces precision.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDD-rTt0uerf",
        "colab_type": "text"
      },
      "source": [
        "(https://github.com/vikash00011/BinaryClassification/blob/master/Capture.PNG) \n",
        "\n",
        "Figure 3-3. Decision threshold and precision/recall tradeoff"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3GFwQlUY1q6y",
        "colab_type": "text"
      },
      "source": [
        "Scikit-Learn does not let you set the threshold directly, but it does give you access to the decision scores that it uses to make predictions. Instead of calling the classifier’s predict() method, you can call its decision_function() method, which returns a score for each instance, and then make predictions based on those scores using any threshold you want:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E27PJLaI12tj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_scores=(sgd_clf.decision_function([some_digit]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CSQ_gZgF120z",
        "colab_type": "code",
        "outputId": "acb4ae5b-f966-40c4-95f2-d6b1c1989134",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "y_scores"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-31893.03095419, -34419.69069632,  -9530.63950739,\n",
              "          1823.73154031, -22320.14822878,  -1385.80478895,\n",
              "        -26188.91070951, -16147.51323997,  -4604.35491274,\n",
              "        -12050.767298  ]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4k9YtJoUcr6X",
        "colab_type": "code",
        "outputId": "9c841e01-36ed-4b7c-b0ad-a270ef508442",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "threshold = 0\n",
        "y_some_digit_pred = (y_scores > threshold)\n",
        "y_some_digit_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False,  True, False, False, False, False, False,\n",
              "        False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kuKeE0tMdDPN",
        "colab_type": "text"
      },
      "source": [
        "The SGDClassifier uses a threshold equal to 0, so the previous code returns the same result as the predict() method (i.e., True). Let’s raise the threshold:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4YntkX4dHMM",
        "colab_type": "code",
        "outputId": "4e318e29-6242-48c6-9ca5-aba4905c305d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "threshold = 8000\n",
        "y_some_digit_pred = (y_scores > threshold)\n",
        "y_some_digit_pred"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[False, False, False, False, False, False, False, False, False,\n",
              "        False]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kPbqVoRvdU9n",
        "colab_type": "text"
      },
      "source": [
        "This confirms that raising the threshold decreases recall. The image actually represents a 5, and the classifier detects it when the threshold is 0, but it misses it when the threshold is increased to 8,000.\n",
        "\n",
        "Now how do you decide which threshold to use? For this you will first need to get the scores of all instances in the training set using the cross_val_predict() function again, but this time specifying that you want it to return decision scores instead of predictions:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "brab9Pysdguy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method=\"decision_function\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7v0-toPPdqtx",
        "colab_type": "text"
      },
      "source": [
        "Now with these scores you can compute precision and recall for all possible thresholds using the precision_recall_curve() function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_5DJn8GdxnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_recall_curve\n",
        "precisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iiioO59od95k",
        "colab_type": "text"
      },
      "source": [
        "Finally, you can plot precision and recall as functions of the threshold value using Matplotlib:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZDmsioBeA6z",
        "colab_type": "code",
        "outputId": "bd16464b-ea2c-450f-9508-380de9236c36",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "def plot_precision_recall_vs_threshold(precisions, recalls, thresholds):\n",
        "  plt.plot(thresholds, precisions[:-1], \"b--\", label=\"Precision\")\n",
        "  plt.plot(thresholds, recalls[:-1], \"g-\", label=\"Recall\")\n",
        "  [...] # highlight the threshold, add the legend, axis label and grid\n",
        "plot_precision_recall_vs_threshold(precisions, recalls, thresholds)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nLqTJXSmlXEiTu1JKuZAmd6WUcqH/Bw1wJ2p4vBOMAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AAEcXerCee7Z",
        "colab_type": "text"
      },
      "source": [
        "You may wonder why the precision curve is bumpier than the recall curve in Figure. The reason is that precision may sometimes go down when you raise the threshold (although in general it will go up). To understand why, look back at Figure and notice what happens when you start from the central threshold and move it just one digit to the right: precision goes from 4/5 (80%) down to 3/4 (75%). On the other hand, recall can only go down when the threshold is increased, which explains why its curve looks smooth."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02Faew9ve2bO",
        "colab_type": "text"
      },
      "source": [
        "Another way to select a good precision/recall tradeoff is to plot precision directly against recall, as shown in Figure below (the same threshold as earlier is highlighed).\n",
        "\n",
        "(https://github.com/vikash00011/BinaryClassification/blob/master/Capture4.PNG)\n",
        "\n",
        "Figure. Precision versus recall"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BezyxCHCfnWo",
        "colab_type": "text"
      },
      "source": [
        "You can see that precision really starts to fall sharply around 80% recall. You will probably want to select a precision/recall tradeoff just before that drop—for example, at around 60% recall. But of course the choice depends on your project. So let’s suppose you decide to aim for 90% precision. You look up the first plot and find that you need to use a threshold of about 8,000. To be more precise you can search for the lowest threshold that gives you at least 90% precision (np.argmax() will give us the first index of the maximum value, which in this case means the first True value):\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EHNKvz5Nf0KM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "threshold_90_precision = thresholds[np.argmax(precisions >= 0.90)] # ~7816"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uSsfCv7of37D",
        "colab_type": "text"
      },
      "source": [
        "To make predictions (on the training set for now), instead of calling the classifier’s predict() method, you can just run this code:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PH3cpjI8f-rH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_train_pred_90 = (y_scores >= threshold_90_precision)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZyj8PlrgCoC",
        "colab_type": "text"
      },
      "source": [
        "Let’s check these predictions’ precision and recall:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xEB8JxPsgESM",
        "colab_type": "code",
        "outputId": "c8ea5d4a-3b42-4493-c8d6-5f1119a8327f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "print(precision_score(y_train_5, y_train_pred_90))\n",
        "\n",
        "print()\n",
        "\n",
        "print(recall_score(y_train_5, y_train_pred_90))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9000345901072293\n",
            "\n",
            "0.4799852425751706\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiHWxHlZgWiO",
        "colab_type": "text"
      },
      "source": [
        "Great, you have a 90% precision classifier ! As you can see, it is fairly easy to create a classifier with virtually any precision you want: just set a high enough threshold, and you’re done. Hmm, not so fast. A high-precision classifier is not very useful if its recall is too low.\n",
        "\n",
        "**Note**  If someone says “let’s reach 99% precision,” you should ask, “at what recall?”"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mOTfrx5AgyG-",
        "colab_type": "text"
      },
      "source": [
        "e.) The ROC Curve\n",
        "\n",
        "**_________________**  **_________________**  **_________________**  **_________________**\n",
        "\n",
        "The receiver operating characteristic (ROC) curve is another common tool used with binary classifiers. It is very similar to the precision/recall curve, but instead of plotting precision versus recall, the ROC curve plots the true positive rate (another name for recall) against the false positive rate. The FPR is the ratio of negative instances that are incorrectly classified as positive. It is equal to one minus the true negative rate, which is the ratio of negative instances that are correctly classified as negative. The TNR is also called specificity. Hence the ROC curve plots sensitivity (recall) versus \n",
        "1 – secificity.\n",
        "\n",
        "To plot the ROC curve, you first need to compute the TPR and FPR for various threshold values, using the roc_curve() function:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wzAi0dLdg6Ik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "fpr, tpr, thresholds = roc_curve(y_train_5, y_scores)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_kgQ-_shBTS",
        "colab_type": "text"
      },
      "source": [
        "Then you can plot the FPR against the TPR using Matplotlib. This code produces the plot in below Figure:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWhvtjUdhJuP",
        "colab_type": "code",
        "outputId": "07eb3ef2-f5c1-4af9-da47-f0358c36baf3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "def plot_roc_curve(fpr, tpr, label=None):\n",
        " plt.plot(fpr, tpr, linewidth=2, label=label)\n",
        " plt.plot([0, 1], [0, 1], 'k--') # dashed diagonal\n",
        " [...] # Add axis labels and grid\n",
        "plot_roc_curve(fpr, tpr)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAIABJREFUeJzt3Xl4FFW6x/Hv6e6sELYQ1hBCWIQQ\nEDGCiICIsigI6MWLIi43isjooI7j4KiIDDKA4AKyK4orouOCV+7gjMs4gyIgm4ACMRAS1iSEhISk\n08u5f3R3jAikgU6qq/v9PE8eeql0v0WSX05OnXpLaa0RQggRWixGFyCEECLwJNyFECIESbgLIUQI\nknAXQogQJOEuhBAhSMJdCCFCkIS7EEKEIAl3IYQIQRLuQggRgmxGvXHjxo11cnKyUW8vhBCm9P33\n3+drrROq286wcE9OTmbjxo1Gvb0QQpiSUirbn+1kWkYIIUKQhLsQQoQgCXchhAhBEu5CCBGCJNyF\nECIEVRvuSqllSqmjSqntZ3heKaXmKqUylVLblFLdA1+mEEKIc+HPyP01YPBZnh8CtPd+jAMWXnhZ\nQgghLkS169y11l8rpZLPsslw4HXtuV7fOqVUA6VUc631oQDVKIQQtabc4eJYaQVFZQ5cbu350Bq3\n77b3/uGicqIjrDjdbhwujcPlZm9eKQ1iI6hwurG73Gw/UESzejE4XG4cLje7cvJwlRUzok83Hrq2\nQ43uRyBOYmoJ5FS5n+t97DfhrpQah2d0T1JSUgDeWggRDFxujdPtxu2m8l+X/uWxkxXOKiEJbu0J\nSbfW3tuex06UO3G53WgNDrfG6XLjdGn2FpTSICYCl9a4XJ7X8QWt063ZcbCIpEaxOF2/hK/T7dk2\nM6+EKJuFHQeLaVYv+peg9tVQpa4Kl7vG/o/Ksrdy7O/zsETVIS5+mSnC3W9a6yXAEoD09HS5MrcI\nO1prKlxuTtpdHC9zVI7oHC7NsVI7CuUJJbfb+6/G6dJkHztJvWgbdqebffmlWJQi0mbBpTW6MijB\n7Q1Ml/aEpdut2ZJznHZN6qL1L6Hqu+35qHLbDQeOl1HhdBNfNxKt+VUIu095DZdbU+ZwGf3fCsBa\nCqrd5nBx+Tm9ZsdmcURYLVgsCqsCm8WCxQJWi8LthqMnyklrWR+bxUKkTWGzWDhUVE5ay3pE2ixE\nWi0cySvgqzef558fvkOLpDb8fsosbrzukvPdTb8FItwPAK2q3E/0PiaEIdze0dzJCicVLndlQPpG\neU63m8JSB0pRGa4HCsuIirBS4XRT4XSz52gJ9WMicLjclJQ7+elwMS0axOBw/RK8FU4332cX0r5p\nXGXAVh0V+kaoDpcmv8ROpM1ChbPmRoZnc6jo3EINILew7Jw/JzrCglUpLBaFzaKwWhQWpXBrTX5J\nBR2a1sWiPI9ZLZ7tLIrKz7Eo2Jd/ks4t6hEdaSXCorBZLdgsitzCMjq3rOd9Xc/72Kye1wEotTtp\n1TD2V+/t+3C5NUmNYqkbZSMm0lr5/p73pbJOq/dzlVLnvO+n43K56NJlKLt27eLRRx9lypQpxMTE\nBOS1qxOIcF8F3K+UWgH0BIpkvl2cyjditTvdlNqd2B1unN6QdLo8oVtYWoFba4rKHOQWlhFls1Bq\nd3K4uJxSuwu7082hojKOlVbQIDYSu8NFVn4pcdG2KuHtxl1DfxNuzS067eM/Hir26/N9wW6zKKJs\nFhrERhIbacVmtRBp9YTYz3klpLdu6A0ZS2XYWCyKQ0VldE1sQJTNQlGZg5YNYoiKsHoCSuENR4XV\nQmWAWrwh5XS7aVQnEotSqFPCVPnC1vucL4zrRUdg8b6W1fLLc1bfa1d5n0ibpTJkBRQUFNCoUSOs\nVivPPPMMrVq1Ij09vVZrqDbclVLvAFcBjZVSucBTQASA1noRsBq4DsgETgJ31VSxwnhaa+xONz/n\nlXCstIKjxXY+23kYh8vzZ7vTe2DJ7nSzJec4iQ1jzmsEWJ2qI9ET5c7fPB9hVThcnpRvVi/aE5LW\nX0ZmxWVOrBZFm8Z1iLAqIqwW9h87SffWDYm0WoiyWTh6wk7nFvWIslkqR3IJcVFEWD0jxwhv6EZY\nLdSJsv5qRGqtEn6+YIyLiiDK5vkTX4QmrTVvvfUWEydOZMaMGdxzzz2MHDnSkFr8WS1zSzXPa+B3\nAatIGMLpcnPgeBk/HChi+4FiCkrsrNtbQKPYSLbmFhETYQXA7nSd08i4arBbLYqYCCtKeQI5JaEO\nEb7RqdUTuvuPnaRnm3g0njdpm1CXOlE2mtaLIjbSRqTNs3o3vk4ksZE2omwW4qJtlSPHCIuEpzBG\nTk4O48ePZ/Xq1Vx++eX07t3b0HoMa/krapbTe5CuwuWmxO5kb14pOw4W4XC5yTlWxoZ9x4iLtrE1\nt4i4aNtpR78AOcc84Vz1oJkvO2MjbfRs04joCCtRERau6dSUulE2IqwW7+hWERcdQYPYCOrHRBBh\nlROiRWh65513uPfee3G5XLzwwgvcf//9WK1WQ2uScDchp8vN4eJycgvLOFxUznd7j1Fqd5J3ws6m\n/YXYz/GgXdVgrx8TQZvGdWjTuA5dWtanef1o2jetS92oCOrF2Ii0WrBJSAvxKw0bNqRnz54sWbKE\nNm3aGF0OAMozq1L70tPTtVyso3rlDhfrsgpYs+MIm7IL2XXkhN+fG2WzVC7HOnaygsSGMSTH16Ff\nhwSa148h0mYhqVEsDWIjaFQnUkbWQvjJ6XTy/PPPU1FRweOPPw545tsDtcrmbJRS32utqz06KyP3\nIOFya46eKGdrThE7DhaRW1hGbuFJNuwrPOPnNKvnGVW3TahLk3pRdGgSR7P60bSOjyUuOqIWqxci\nfGzdupWMjAy+//57br755spQr41gPxcS7gYpKLHz5a48Vm09SN4J+1mX0zWuG0XbhDr07ZBA18T6\ndGlZnwaxkbVYrRDCbrczbdo0ZsyYQaNGjXjvvfe46aabgi7UfSTca8n+gpO8vX4/y7/Zd9Yz+mIj\nrSQ1iuXylHj6tG9MSkJdkuNjg/YbSIhwsWfPHmbOnMmtt97Kc889R3x8vNElnZWEew04VFTGp9sO\nkZVfykebD3Cy4sxhPqBjE0Zc0pKeKY1oEhddi1UKIapTUlLCxx9/zJgxY0hLS+Onn34iJSXF6LL8\nIuEeIPvyS5nxfz+xMbuQ/BL7abdpm1CHgZ2bMbhzM9Ja1pcz+oQIYv/4xz8YN24c2dnZdO/enU6d\nOpkm2EHC/by53Zq1P+ez4Muf+Tbrtw2L2jSuw9CuzenUvB5N4qLo1qqBLCEUwgQKCwt55JFHWLZs\nGR06dOBf//oXnTp1Mrqscybhfo5K7U4mffADn2w9+JvnurVqwKj0REZ0a0mdKPmvFcJsXC4XvXv3\nZvfu3Tz22GNMnjyZ6GhzTpdKAvkpu6CUZf/Zy/Jvs3/1eLsmdZk6vDOXJTeSdeJCmFR+fn5lo6/p\n06eTlJRE9+7mvmKohPtZuN2a977P4Z31OWzJOV75eKTNwuShqdzaI0n6mAhhYlpr3njjDR588EFm\nzJjBuHHjGDFihNFlBYSE+xls2l/I4x9u/9X686RGsTx4TXtu7J5oYGVCiEDIzs7m3nvvZc2aNVxx\nxRX07dvX6JICSsL9ND7afIAH391Sef/P13Vk5CWJJMRFGViVECJQ3nzzTe677z601sybN48JEyZg\nsYTWtKqEexVaa1745x5e/HwPAJclN+TJoal0TWxgcGVCiEBKSEigd+/eLF68mNatWxtdTo2QcPfK\nyith4oot/HDAc7WdW3smMW14msypCxECHA4Hc+bMweFw8OSTTzJo0CAGDhwY0md+h324a62Z89lu\nXvoys/KxZ/+rK6PSW53ls4QQZrF582YyMjLYvHkzo0ePDtpGX4EW1uHucLm589X1rM30nITUs00j\n/jjoItKTGxlcmRDiQpWXlzN16lRmzZpF48aN+dvf/saNN95odFm1JmzDvdTu5KaF3/DTYU9/9Gkj\n0rjt8tCcexMiHGVmZjJ79mxuv/125syZQ8OGDY0uqVaFbbg/+rdtlcG+9PZ0rk1tanBFQogLVVJS\nwocffsjYsWNJS0tj165dQXNlpNoWWmt//DT1k518uu0QAAvHdJdgFyIErFmzhs6dO3PHHXfw448/\nAoRtsEMYhvsb67JZtnYvAJOGdGRIl+YGVySEuBAFBQXccccdDB48mNjYWP7973+bstFXoIXVtMzW\nnOM89fF2AO68Ipnx/doaXJEQ4kL4Gn1lZmby+OOP88QTT5i20VeghU24u9yayR9vx62hT/vGPDUs\n1eiShBDnKS8vj/j4eKxWKzNnzqR169Z069bN6LKCSthMy7zynyy25hYRE2FlzqiLQ36NqxChSGvN\nq6++SocOHVi6dCkAw4cPl2A/jbAI94ISO8/9YzcAU25IpUk9+bNNCLPZt28fgwYN4n/+53/o0qUL\n/fv3N7qkoBby4a615qGVWyl3uLmoaRz/damceSqE2bzxxhukpaXx7bffsmDBAr766is6dOhgdFlB\nLeTn3DftP87Xu/OItFlYcvulct1SIUyoadOm9O3bl0WLFpGUlGR0OaYQ8uH+vHc6ZkS3FrSOr2Nw\nNUIIfzgcDmbNmoXL5WLy5MkMHDiQgQMHGl2WqYT0tMzPeSX8JzMfq0Xxx0EdjS5HCOGHTZs2cdll\nl/HEE0+wa9cutNZGl2RKfoW7UmqwUmqXUipTKTXpNM8nKaW+VEptVkptU0pdF/hSz92CL38GYHBa\nM7nQhhBBrqysjEmTJtGjRw+OHDnChx9+yFtvvSUr285TteGulLIC84EhQCpwi1Lq1EXiTwArtdaX\nAKOBBYEu9FwdLirn0x8OApBxZfiegiyEWWRlZfHcc89x5513snPnzpC5lqlR/Bm59wAytdZZWusK\nYAUw/JRtNFDPe7s+cDBwJZ6f9zbmUO5wc3GrBnRPCq9ucEKYRXFxMa+99hoAnTt3Zs+ePbz88sth\n18GxJvgT7i2BnCr3c72PVTUFuE0plQusBh4ISHXnSWvNig2eksf1STGyFCHEGaxevZq0tDQyMjIq\nG32F6iXvjBCoA6q3AK9prROB64A3lFK/eW2l1Dil1Eal1Ma8vLwAvfVvrcs6xoHjZSTERTEkrVmN\nvY8Q4tzl5+czduxYrr/+euLi4li7dq00+qoB/oT7AaDqmT+J3seqygBWAmitvwWigcanvpDWeonW\nOl1rnZ6QkHB+Ffth5UbPqP2m7olyDVQhgoiv0deKFSuYPHkymzZt4vLLLze6rJDkzzr3DUB7pVQb\nPKE+Grj1lG32AwOA15RSnfCEe80Nzc9Ca81/MvMBGN6thRElCCFOceTIERISErBarcyePZvWrVvT\ntWtXo8sKadWO3LXWTuB+YA3wI55VMTuUUlOVUjd4N/sDcI9SaivwDnCnNmhx6o6DxeSdsNO4biQd\nm8UZUYIQwktrzSuvvMJFF13EkiVLABg2bJgEey3w6wxVrfVqPAdKqz42ucrtnUDvwJZ2fnyj9v4X\nNZH1sUIYKCsri3vuuYcvvviCfv36cc011xhdUlgJuTNUv/jpKAB9OtTcnL4Q4uyWL19Oly5d2LBh\nA4sWLeKLL76gXbt2RpcVVkKqt0y5w8X32YUAXNnuN8dzhRC1pEWLFlx99dUsXLiQxMREo8sJSyEV\n7jsOFuNya1Ia16FRnUijyxEibFRUVDBjxgzcbjdTpkzh2muv5dprrzW6rLAWUtMym7yj9suSGxlc\niRDhY8OGDVx66aU89dRTZGVlSaOvIBFS4f7CPz3tfbslNTC4EiFC38mTJ3nkkUe4/PLLKSwsZNWq\nVbz++uuykCFIhEy4l9qdVLjcAFyeEm9wNUKEvr179zJv3jzuueceduzYwbBhw4wuSVQRMnPu/96T\nh8OlqRtlo01juSiHEDWhqKiIDz74gLvuuovOnTuTmZlJq1Zy6cpgFDIj929/LgBgbC9pPCRETfj0\n00/p3Lkzd999Nz/99BOABHsQC5lw/9duT7cDae8rRGDl5eUxZswYhg4dSsOGDfn222/p2FGubBbs\nQmJaRmtNQUkFAMnxsQZXI0TocLlcXHnllezdu5enn36aSZMmERkpy4zNICTCPe+EnRN2JwBtE+oa\nXI0Q5nf48GGaNGmC1Wplzpw5JCcnk5aWZnRZ4hyExLTMjkPFALRrUlda/ApxAdxuN4sXL6ZDhw4s\nXrwYgKFDh0qwm1BIhHt2fikA9WMiDK5ECPPKzMxkwIABjB8/nssuu4xBgwYZXZK4ACER7ruOnADg\nui7NDa5ECHN69dVX6dKlC5s2bWLp0qX885//JCVFLlFpZiEx577XO3JPSZD17UKcj6SkJAYNGsT8\n+fNp2fLUSyQLMwqJcM85VgZAm3gJdyH8Ybfb+etf/4rb7Wbq1KkMGDCAAQMGGF2WCCDTT8torSko\ntQOQEBdlcDVCBL/vvvuOSy+9lKeffpr9+/dLo68QZfpwLzzpoNzhpm6UjdhIq9HlCBG0SktLefjh\nh+nVqxdFRUX87//+L6+99po0+gpRpg/33MKTACQ2jJFvUiHOIjs7mwULFjB+/Hh27NjB9ddfb3RJ\nogaZfs79UFE5AM3rRxtciRDB5/jx47z//vvcfffdpKamkpmZKVdGChOmH7kfP+lpO9BQrrwkxK98\n/PHHpKamMn78+MpGXxLs4cP04b7/mGdapmWDGIMrESI4HD16lNGjRzNixAgSEhJYt26dNPoKQ6af\nlvGtcW/XRHrKCOFyuejduzf79+9n2rRpPProo0REyJnb4cj04X7YO+eeUFeWQYrwdfDgQZo1a4bV\nauXFF18kOTmZ1NRUo8sSBjL9tMym/ccBaC7TMiIMud1uFi5cSMeOHVm0aBEA1113nQS7MH+4R9k8\nuyAnMIlws3v3bvr378+ECRPo2bMnQ4YMMbokEURMHe4nK5zYnW6ibBbqyAlMIoy88sorXHzxxWzb\nto1ly5bx2Wef0aZNG6PLEkHE1HPux0o9yyAb1YmUE5hEWElOTmbIkCHMnz+f5s2lG6r4LVOH+9ET\n0lNGhAe73c5f/vIXAKZNmyaNvkS1TD0tk+cLd1kpI0LYN998Q7du3XjmmWc4dOiQNPoSfjF1uOeX\neMI9vq6cnSpCT0lJCRMnTuTKK6/k5MmT/P3vf+eVV16RKUjhF7/CXSk1WCm1SymVqZSadIZtblZK\n7VRK7VBKvR3YMk+v0DvnHi8jdxGC9u/fz+LFi/nd737H9u3b5bJ34pxUO+eulLIC84FrgVxgg1Jq\nldZ6Z5Vt2gOPAb211oVKqSY1VXBVuYWei3Q0jJUz8ERoKCws5L333mPcuHGkpqaSlZVFixYtjC5L\nmJA/I/ceQKbWOktrXQGsAIafss09wHytdSGA1vpoYMs8PV+4R0fIMkhhfh9++CGpqalMmDCBXbt2\nAUiwi/PmT7i3BHKq3M/1PlZVB6CDUmqtUmqdUmrw6V5IKTVOKbVRKbUxLy/v/CquwhfqsZGmXvQj\nwtzhw4cZNWoUN954I82aNWP9+vVcdNFFRpclTC5QqWgD2gNXAYnA10qpLlrr41U30lovAZYApKen\nX/Ah/+IyByC93IV5uVwu+vTpQ05ODtOnT+eRRx6RRl8iIPwJ9wNAqyr3E72PVZULfKe1dgB7lVK7\n8YT9hoBUeQYn7E4A6sfID4Mwl9zcXFq0aIHVamXu3Lm0adNG2vKKgPJnWmYD0F4p1UYpFQmMBlad\nss1HeEbtKKUa45mmyQpgnad1zHthbAl3YRZut5t58+bRsWNHFi5cCMCQIUMk2EXAVRvuWmsncD+w\nBvgRWKm13qGUmqqUusG72RqgQCm1E/gS+KPWuqCmivbWxfGTnmkZWecuzOCnn36ib9++/P73v+fK\nK69k6NChRpckQphfc+5a69XA6lMem1zltgYe9n7UCrvTjd3pJsKqiJHVMiLIvfzyy9x///3Exsay\nfPlyxo4dKycjiRpl2mUmpd759rpRNvkhEUGvbdu2DBs2jJdeeommTZsaXY4IA6YN9+JyT7jHRct8\nuwg+5eXlTJ06FYDp06fTv39/+vfvb3BVIpyYtrfMweOeE5jqxZj295MIUWvXrqVbt2789a9/JS8v\nTxp9CUOYNtzLKlwAFJY6DK5ECI8TJ07wwAMP0KdPH+x2O2vWrGHp0qUybSgMYdpwL/KewJSe3NDg\nSoTwyM3N5eWXX+aBBx7ghx9+YODAgUaXJMKYaec0iss94S5r3IWRCgoKWLlyJffddx+dOnUiKytL\nrowkgoJpR+7FZZ4DqvXkgKowgNaa999/n9TUVH7/+99XNvqSYBfBwrThfvREOQB1o037x4cwqUOH\nDnHTTTcxatQoWrVqxcaNG6XRlwg6pk3GI8WecLfKwSpRi3yNvg4cOMCsWbN46KGHsNlM+2MkQphp\nvyt969ttVgl3UfNycnJo2bIlVquV+fPn06ZNGzp06GB0WUKckWmnZbbmeroJN6sn7X5FzXG5XMyd\nO/dXjb4GDRokwS6CnmnD3dfD3SUniIga8uOPP9KnTx8mTpxIv379GDZsmNElCeE304b7Me/JS03i\nZOQuAm/JkiV069aN3bt388Ybb/Dpp5+SlJRkdFlC+M20c+5ZeSUARNlM+/tJBLH27dszcuRI5s6d\nS5MmtXK9dyECyrThnhAXRW5hGfXkJCYRAGVlZUyZMgWlFDNmzJBGX8L0TDvsLbH7ukKa9veTCBJf\nf/01F198MbNmzaKoqEgafYmQYMpw11pXXhxb2g+I81VcXMyECRPo168fLpeLzz//nIULF0qjLxES\nTBnuZQ4Xbu2Zb4+wmnIXRBA4ePAgr732Gg8//DDbtm3j6quvNrokIQLGlHMavo6QDWJl1C7OTX5+\nPitXrmTChAl07NiRvXv3ypWRREgy5bDXd4m9OlGm/N0kDKC15t133yU1NZUHH3yQ3bt3A0iwi5Bl\n0nD3XKijTqSEu6jewYMHGTFiBKNHj6Z169Z8//33coapCHmmTMcyhyfcYyKtBlcigp3L5aJv374c\nOHCA2bNnM3HiRGn0JcKCKb/LfeEeHSHhLk4vOzubxMRErFYrCxYsICUlhXbt2hldlhC1xpTTMuXe\n66fGRJiyfFGDXC4Xzz33HJ06daps9DVw4EAJdhF2TDlytzvdgIzcxa9t376djIwM1q9fz9ChQxkx\nYoTRJQlhGFMOfe1Oz8g9Uta4C69FixbRvXt3srKyePvtt1m1ahWJiYlGlyWEYUyZjhXekXukNA0L\ne75WAZ06dWLUqFHs3LmTW265Rc4yFWHPlNMylatlZFombJ08eZLJkydjtVqZOXMm/fr1o1+/fkaX\nJUTQMOXQ1+HyjNZk5B6evvrqK7p27cqcOXMoKSmRRl9CnIYp09E3LSN9ZcJLUVER9957b2Ur3i++\n+IL58+fLFIwQp+FXOiqlBiuldimlMpVSk86y3U1KKa2USg9cib/lcMmcezg6dOgQb775Jo888gjb\ntm2TfutCnEW1c+5KKSswH7gWyAU2KKVWaa13nrJdHDAR+K4mCq3KtxRSVsuEvry8PFasWMEDDzxA\nx44d2bdvHwkJCUaXJUTQ8ycdewCZWussrXUFsAIYfprt/gLMBMoDWN9plfvOUJX2AyFLa83bb79N\np06d+MMf/lDZ6EuCXQj/+BPuLYGcKvdzvY9VUkp1B1pprT8NYG1n5JuWibDIXGsoysnJYdiwYYwZ\nM4Z27dqxefNmafQlxDm64KWQSikL8Bxwpx/bjgPGARd0JXmnd7WMHFANPU6nk6uuuorDhw/z/PPP\n88ADD2C1yl9oQpwrf8L9ANCqyv1E72M+cUAa8JV31UIzYJVS6gat9caqL6S1XgIsAUhPTz/v9WsH\ni8o8xVtl5B4q9u3bR6tWrbDZbCxevJiUlBRSUlKMLksI0/Jn6LsBaK+UaqOUigRGA6t8T2qti7TW\njbXWyVrrZGAd8JtgDyTfyN23JFKYl9PpZPbs2XTq1IkFCxYAcM0110iwC3GBqh25a62dSqn7gTWA\nFVimtd6hlJoKbNRarzr7KwRePe9FsevKlZhMbdu2bWRkZLBx40aGDx/OTTfdZHRJQoQMv9JRa70a\nWH3KY5PPsO1VF17W2fkOqMrFOsxrwYIFTJw4kYYNG/Luu+8yatQoORlJiAAy5RHJypOY5ICq6fha\nBaSlpTF69Gh27tzJzTffLMEuRICZcl7DN+duk3A3jdLSUp544glsNhvPPvssffv2pW/fvkaXJUTI\nMmU6VvjWuctqGVP4/PPP6dKlCy+88AJ2u10afQlRC8wZ7nIlJlM4fvw4d999N9dccw02m42vv/6a\nuXPnyhSMELXAnOHukq6QZnDkyBFWrFjBn/70J7Zu3UqfPn2MLkmIsGHKOXc5oBq8fIE+ceJELrro\nIvbt20fjxo2NLkuIsGPKdHQ4ve0HbPLnfbDQWvPmm2+SmprKo48+yp49ewAk2IUwiCnD3XeZvWib\nzLkHg/3793P99dczduxYLrroIrZs2UL79u2NLkuIsGbKaRmnd1pGessYz9fo6+jRo8ydO5cJEyZI\noy8hgoApw93hlq6QRsvKyqJ169bYbDaWLl1K27ZtSU5ONrosIYSXKdOxcuQu/dxrndPpZObMmaSm\npjJ//nwABgwYIMEuRJAx3cjd5da4NSgFVgn3WrVlyxYyMjLYtGkTI0eOZNSoUUaXJIQ4A9ON3H3L\nILVGToapRS+99BKXXXYZBw4c4P333+eDDz6gefPmRpclhDgD04W70zvfHmkzXemm5GsV0LVrV8aM\nGcPOnTulNa8QJmDKaRmAKAn3GlVSUsLjjz9OREQEs2fPlkZfQpiM6RLSF+5yMLXmfPbZZ6SlpTFv\n3jwcDoc0+hLChEwX7k63Z87dajFd6UGvsLCQu+66i0GDBhEdHc3XX3/Niy++KMc2hDAh0yWkN9uR\nJe6Bd/ToUd5//30ee+wxtmzZwpVXXml0SUKI82S6OXffyN0mI/eAOHz4MO+88w4PPfRQZaOv+Ph4\no8sSQlwg0yWkr5e7tB64MFprli9fTmpqKo899lhloy8JdiFCg+nCvXIppMzLnLd9+/YxePBg7rzz\nTlJTU6XRlxAhyHzTMt7rp8q3zet1AAAM00lEQVTZqefH6XTSv39/8vPzmT9/PuPHj8ciU1xChBzT\nhXvlUkiZljknmZmZtGnTBpvNxrJly0hJSaF169ZGlyWEqCGmG7LJUshz43A4mD59Op07d65s9NW/\nf38JdiFCnOlG7k45iclvmzZtIiMjgy1btjBq1Cj++7//2+iShBC1xHTD3+IyByBz7tWZO3cuPXr0\n4PDhw3zwwQesXLmSpk2bGl2WEKKWmC7cfRfoyDxaYnAlwcnXKuCSSy7h9ttvZ+fOnYwcOdLgqoQQ\ntc100zK+A6pdE+sbXElwOXHiBI899hhRUVHMmTOHPn360KdPH6PLEkIYxHQjd5lz/62///3vpKWl\nsWDBArTW0uhLCGG+cHdVrpaRcC8oKOCOO+5gyJAh1KlTh7Vr1/Lcc89Joy8hhBnD3fOv9JbxhPuH\nH37Ik08+yebNm+nVq5fRJQkhgoRfCamUGqyU2qWUylRKTTrN8w8rpXYqpbYppT5XStXYImpnmI/c\nDx06xOzZs9Fa06FDB7Kzs5k6dSpRUVFGlyaECCLVhrtSygrMB4YAqcAtSqnUUzbbDKRrrbsC7wOz\nAl2oj6/9QLjNuWutWbZsGZ06deLJJ58kMzMTgIYNGxpcmRAiGPkzcu8BZGqts7TWFcAKYHjVDbTW\nX2qtT3rvrgMSA1vmLyq88zIRYdQ4bO/evQwcOJCMjAwuvvhitm7dKo2+hBBn5c9SyJZATpX7uUDP\ns2yfAfzf6Z5QSo0DxgEkJSX5WeKvOb3hbg2T3jJOp5Orr76agoICFi5cyLhx46TRlxCiWgFd566U\nug1IB/qd7nmt9RJgCUB6evp5rdfzLYWMCPFpmT179pCSkoLNZuPVV1+lbdu2tGrVyuiyhBAm4c8Q\n8ABQNVUSvY/9ilLqGuBx4AattT0w5f1W5Zx7iE7LOBwOpk2bRlpaGi+99BIAV111lQS7EOKc+DNy\n3wC0V0q1wRPqo4Fbq26glLoEWAwM1lofDXiVVYTySUwbN24kIyODbdu2MXr0aG655RajSxJCmFS1\nw1+ttRO4H1gD/Ais1FrvUEpNVUrd4N3sWaAu8J5SaotSalVNFbwvv9RzI8Sy/cUXX6Rnz57k5+fz\n8ccf884779CkSROjyxJCmJRfc+5a69XA6lMem1zl9jUBruuMmjeIBuBocY3N/NQqrTVKKdLT08nI\nyGDWrFk0aNDA6LKEECZnusZhvrYpSY1ijS3kAhUXF/OnP/2J6Ohonn/+eXr37k3v3r2NLksIESJM\nd1TS1xTLYuL+KatXr6Zz584sWbIEm80mjb6EEAFnunD3Hk/FjNmen5/PbbfdxvXXX0/9+vX55ptv\nePbZZ6XRlxAi4EwX7hrfyN3gQs5DYWEhn3zyCU899RSbNm2iZ8+znQsmhBDnz3Rz7r+M3M2R7gcO\nHOCtt97ij3/8I+3btyc7O1sOmAohapzpRu5u7/x0sGe71pqlS5eSmprKlClT+PnnnwEk2IUQtcJ0\n4e6dlQnqA6o///wzAwYMYNy4cXTv3p1t27bRrl07o8sSQoQRE07LeEfuBtdxJk6nkwEDBnDs2DEW\nL17M3XffLY2+hBC1znThroN05L5r1y7atm2LzWZj+fLltG3blsTEGut8LIQQZ2W6IWWwLYWsqKjg\n6aefpkuXLsyfPx+Afv36SbALIQxlupH7LwdUjU/39evXk5GRwfbt27n11lsZM2aM0SUJIQRgwpG7\nj9Hr3F944QV69epVuXb9rbfeonHjxsYWJYQQXqYLd7fB7Qd8rQJ69OjBPffcw44dOxg6dKghtQgh\nxJmYeFqmdt+3qKiIRx99lJiYGF544QWuuOIKrrjiitotQggh/GS6kfuBwjKgdufcP/nkE1JTU3n5\n5ZeJioqSRl9CiKBnunCPi44A4FhJRY2/V15eHrfeeis33HAD8fHxrFu3jpkzZwbFwVwhhDgb04V7\nTIQVgPi6kTX+XkVFRaxevZqnn36ajRs3ctlll9X4ewohRCCYds49wlozo+ecnBzefPNNJk2aRLt2\n7cjOzqZ+/fo18l5CCFFTTDdy9812B3pqxO12s2jRIjp37sy0adMqG31JsAshzMh04V4TvWX27NnD\n1VdfzX333UePHj344YcfpNGXEMLUTDctE+iukE6nk2uvvZbjx4/zyiuvcNddd8kBUyGE6Zku3AO1\nzv3HH3+kffv22Gw23njjDdq2bUuLFi0CUKEQQhjPdNMyv8y5n9/n2+12nnrqKbp27cpLL70EQJ8+\nfSTYhRAhxXQj9wtp+btu3ToyMjLYuXMnY8eOZezYsQGuTgghgoPpRu7u8zw7dM6cOVxxxRWcOHGC\n1atX8/rrrxMfHx/g6oQQIjiYLtx90e7vyN3tdgPQq1cvxo8fz/bt2xkyZEgNVSeEEMHBhNMy/h1Q\nPX78OH/4wx+IjY1l3rx50uhLCBFWzDdy92PO/aOPPiI1NZXly5cTFxcnjb6EEGHHdOF+tpOYjh49\nys0338zIkSNp2rQp69evZ/r06bJuXQgRdkwX7vos11AtLi7mH//4B8888wzr16+ne/futVucEEIE\nCb/CXSk1WCm1SymVqZSadJrno5RS73qf/04plRzoQn1O7S2zf/9+nnnmGbTWtGvXjv379/PnP/+Z\niIiImipBCCGCXrXhrpSyAvOBIUAqcItSKvWUzTKAQq11O+B5YGagC/XxzZ9rt5sFCxbQuXNnpk+f\nXtnoKy4urqbeWgghTMOfkXsPIFNrnaW1rgBWAMNP2WY4sNx7+31ggKqhiW6twVGQy6N33cTvfvc7\nevXqxY4dO6TRlxBCVOHPUsiWQE6V+7lAzzNto7V2KqWKgHggPxBFVuV0OjiycjLF2Hn11Ve54447\n5ICpEEKcolbXuSulxgHjAJKSks7rNerXiSFl1CRm3nUtI3unBbI8IYQIGf6E+wGgVZX7id7HTrdN\nrlLKBtQHCk59Ia31EmAJQHp6+nktPp97yyVwyyXn86lCCBE2/Jlz3wC0V0q1UUpFAqOBVadsswq4\nw3v7v4AvtJw5JIQQhql25O6dQ78fWANYgWVa6x1KqanARq31KuAV4A2lVCZwDM8vACGEEAbxa85d\na70aWH3KY5Or3C4HRgW2NCGEEOfLdGeoCiGEqJ6EuxBChCAJdyGECEES7kIIEYIk3IUQIgQpo5aj\nK6XygOzz/PTG1EBrgyAn+xweZJ/Dw4Xsc2utdUJ1GxkW7hdCKbVRa51udB21SfY5PMg+h4fa2GeZ\nlhFCiBAk4S6EECHIrOG+xOgCDCD7HB5kn8NDje+zKefchRBCnJ1ZR+5CCCHOIqjDPZguzF1b/Njn\nh5VSO5VS25RSnyulWhtRZyBVt89VtrtJKaWVUqZfWeHPPiulbvZ+rXcopd6u7RoDzY/v7SSl1JdK\nqc3e7+/rjKgzUJRSy5RSR5VS28/wvFJKzfX+f2xTSnUPaAFa66D8wNNe+GcgBYgEtgKpp2wzAVjk\nvT0aeNfoumthn/sDsd7b94XDPnu3iwO+BtYB6UbXXQtf5/bAZqCh934To+uuhX1eAtznvZ0K7DO6\n7gvc575Ad2D7GZ6/Dvg/QAGXA98F8v2DeeQeVBfmriXV7rPW+kut9Unv3XV4roxlZv58nQH+AswE\nymuzuBrizz7fA8zXWhcCaK2P1nKNgebPPmugnvd2feBgLdYXcFrrr/Fc3+JMhgOva491QAOlVPNA\nvX8wh/vpLszd8kzbaK2dgO/C3Gblzz5XlYHnN7+ZVbvP3j9XW2mtP63NwmqQP1/nDkAHpdRapdQ6\npdTgWquuZvizz1OA25RSuXiuH/FA7ZRmmHP9eT8ntXqBbBE4SqnbgHSgn9G11CSllAV4DrjT4FJq\nmw3P1MxVeP46+1op1UVrfdzQqmrWLcBrWus5SqleeK7ulqa1dhtdmBkF88j9XC7MzdkuzG0i/uwz\nSqlrgMeBG7TW9lqqraZUt89xQBrwlVJqH565yVUmP6jqz9c5F1iltXZorfcCu/GEvVn5s88ZwEoA\nrfW3QDSeHiyhyq+f9/MVzOEejhfmrnaflVKXAIvxBLvZ52Ghmn3WWhdprRtrrZO11sl4jjPcoLXe\naEy5AeHP9/ZHeEbtKKUa45mmyarNIgPMn33eDwwAUEp1whPuebVaZe1aBdzuXTVzOVCktT4UsFc3\n+ohyNUebr8MzYvkZeNz72FQ8P9zg+eK/B2QC64EUo2uuhX3+J3AE2OL9WGV0zTW9z6ds+xUmXy3j\n59dZ4ZmO2gn8AIw2uuZa2OdUYC2elTRbgIFG13yB+/sOcAhw4PlLLAMYD4yv8jWe7/3/+CHQ39dy\nhqoQQoSgYJ6WEUIIcZ4k3IUQIgRJuAshRAiScBdCiBAk4S6EECFIwl0IIUKQhLsQQoQgCXchhAhB\n/w/gICdgiDYLzgAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmNp9MfuhPrn",
        "colab_type": "text"
      },
      "source": [
        "Once again there is a tradeoff: the higher the recall (TPR), the more false positives (FPR) the classifier produces. The dotted line represents the ROC curve of a purely random classifier; a good classifier stays as far away from that line as possible (toward the top-left corner).\n",
        "\n",
        "One way to compare classifiers is to measure the area under the curve (AUC). A perfect classifier will have a ROC AUC equal to 1, whereas a purely random classifier will have a ROC AUC equal to 0.5. Scikit-Learn provides a function to compute the ROC AUC:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfvt8gtqhakf",
        "colab_type": "code",
        "outputId": "daee744f-836c-4fd3-a2e5-ef7e76cced18",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "roc_auc_score(y_train_5, y_scores)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9604938554008616"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z94xWwudhhc6",
        "colab_type": "text"
      },
      "source": [
        "Since the ROC curve is so similar to the precision/recall (or PR) curve, you may wonder how to decide which one to use. As a rule of thumb, you should prefer the PR curve whenever the positive class is rare or when you care more about the false positives than the false negatives, and the ROC curve otherwise. For example, looking at the previous ROC curve (and the ROC AUC score), you\n",
        "may think that the classifier is really good. But this is mostly because there are few positives (5s) compared to the negatives (non-5s). In contrast, the PR curve makes it clear that the classifier has room for improvement (the curve could be closer to the topright corner)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ENCWdSk_hzdj",
        "colab_type": "text"
      },
      "source": [
        "Let’s train a RandomForestClassifier and compare its ROC curve and ROC AUC score to the SGDClassifier. First, you need to get scores for each instance in the training set. But due to the way it works (see Chapter 7), the RandomForestClassifier class does not have a decision_function() method. Instead it has a predict_proba() method. Scikit-Learn classifiers generally have one or the other. The predict_proba() method returns an array containing a row per instance and a column per class, each containing the probability that the given instance belongs to the given class (e.g., 70% chance that the image represents a 5):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_s3lYN9BiCgd",
        "colab_type": "code",
        "outputId": "d64e4abf-034f-4270-b2f4-014605707dc9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139
        }
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "forest_clf = RandomForestClassifier(random_state=42)\n",
        "y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3,\n",
        " method=\"predict_proba\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
            "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wozbWF7siJR2",
        "colab_type": "text"
      },
      "source": [
        "But to plot a ROC curve, you need scores, not probabilities. A simple solution is to use the positive class’s probability as the score:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXgI2IWmiPf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_scores_forest = y_probas_forest[:, 1] # score = proba of positive class\n",
        "fpr_forest, tpr_forest, thresholds_forest = roc_curve(y_train_5,y_scores_forest)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AE_eP8DTiVDX",
        "colab_type": "text"
      },
      "source": [
        "Now you are ready to plot the ROC curve. It is useful to plot the first ROC curve as well to see how they compare (below Figure):"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mi0D2Wp8ieAs",
        "colab_type": "code",
        "outputId": "7c55c575-8560-4b3d-d940-5d95739dd8c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        }
      },
      "source": [
        "plt.plot(fpr, tpr, \"b:\", label=\"SGD\")\n",
        "plot_roc_curve(fpr_forest, tpr_forest, \"Random Forest\")\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSe5CCJELSXIXQohc6P8BhJHi7+RRUFMAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ayk-jJqNiwSh",
        "colab_type": "text"
      },
      "source": [
        "As you can see in upper Figure , the RandomForestClassifier’s ROC curve looks much better than the SGDClassifier’s: it comes much closer to the top-left corner. As a result, its ROC AUC score is also significantly better:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZB8EBLuEi7Vr",
        "colab_type": "code",
        "outputId": "84b7c28a-5534-4d58-c4bc-66ee4d60bff0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "roc_auc_score(y_train_5, y_scores_forest)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9920527492698306"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1v2t85gFjCdi",
        "colab_type": "text"
      },
      "source": [
        "Try measuring the precision and recall scores: you should find 99.0% precision and 86.6% recall. Not too bad! Hopefully you now know how to train binary classifiers, choose the appropriate metric for your task, evaluate your classifiers using cross-validation, select the precision/recall tradeoff that fits your needs, and compare various models using ROC curves and ROC AUC scores. "
      ]
    }
  ]
}